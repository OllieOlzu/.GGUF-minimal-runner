# .GGUF-minimal-runner
A simple way to run .gguf AIs using llama.cpp.
